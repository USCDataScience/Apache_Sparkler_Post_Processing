{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor:\n",
    "    def __init__(self):\n",
    "        urlList = []\n",
    "\n",
    "    def readDataIntoList(self, filename):\n",
    "        if filename == \"SVM_C5.txt\":\n",
    "            with open(filename, \"r\") as fp:\n",
    "                x = json.load(fp)\n",
    "            return x\n",
    "        \n",
    "        with open(filename, \"r\") as fp:\n",
    "            data = fp.read()\n",
    "            x = ast.literal_eval(data)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def jsondump(self, js, file):\n",
    "        with open(file, 'w') as outfile:\n",
    "            json.dump(js, outfile, indent=4)\n",
    "        \n",
    "    def fetchDomain(selfself, url):\n",
    "        parsed_uri = urlparse(url)\n",
    "        result = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "        #print(result)\n",
    "        return result\n",
    "\n",
    "    def clean(self, urls, minscore, maxscore, file):\n",
    "        finalList = []\n",
    "\n",
    "        for item in urls:\n",
    "            d = dict()\n",
    "            if item[1][1] == \"NaN\":\n",
    "                continue\n",
    "            d[\"url\"] = item[1][0]\n",
    "            d[\"score\"] = item[1][1]\n",
    "            d[\"domain\"] = self.fetchDomain(item[1][0])\n",
    "            finalList.append(d)\n",
    "        # pprint.pprint(finalList, indent=4)\n",
    "        uniqueDomains = dict()\n",
    "        uniqueList = []\n",
    "        for item in finalList:\n",
    "            if item[\"score\"]>=minscore and item[\"score\"]<maxscore:\n",
    "                if item[\"domain\"] in uniqueDomains:\n",
    "                    uniqueDomains[item[\"domain\"]][\"counts\"] += 1\n",
    "                    uniqueDomains[item[\"domain\"]][\"urls\"].append(item[\"url\"])\n",
    "                else:\n",
    "                    uniqueDomains[item[\"domain\"]] = dict()\n",
    "                    uniqueDomains[item[\"domain\"]][\"counts\"] = 1\n",
    "                    uniqueDomains[item[\"domain\"]][\"urls\"] = [item[\"url\"]]\n",
    "        # pprint.pprint(uniqueDomains)   \n",
    "        print(len(uniqueDomains))\n",
    "        self.jsondump(uniqueDomains, \"Final_Data/cleaned_data/\"+file[:2]+\"_top_all.json\")    \n",
    "        return uniqueDomains\n",
    "    \n",
    "    def extract(self, data, top):\n",
    "        totalUnique = len(data) #total unique URLs\n",
    "        finalList = []\n",
    "        if top<totalUnique:\n",
    "            for item in data:\n",
    "                index = randint(0,len(data[item])-1)   \n",
    "                finalList.append(data[item][\"urls\"][index]) \n",
    "        else:\n",
    "            for item in data:\n",
    "                i=0\n",
    "                maxEach = int(top/totalUnique)\n",
    "                while i<maxEach and i<len(data[item][\"urls\"]):\n",
    "                    finalList.append(data[item][\"urls\"][i])\n",
    "                    i+=1\n",
    "            if len(finalList)<top:\n",
    "                dif = top - len(finalList) # more urls needed\n",
    "                i = 0\n",
    "                for item in data:\n",
    "                    if i>= dif:\n",
    "                        break\n",
    "                    count = 0\n",
    "                    while True: \n",
    "                        index = randint(0,len(data[item][\"urls\"])-1)    \n",
    "                        if data[item][\"urls\"][index] not in finalList:\n",
    "                            finalList.append(data[item][\"urls\"][index])\n",
    "                            i+=1\n",
    "                            break\n",
    "                        else:\n",
    "                            if count>len(data[item][\"urls\"]): # exceeds \n",
    "                                break\n",
    "                            count += 1\n",
    "        return finalList         \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_C5.txt\n",
      "--------------\n",
      "Max\n",
      "--------------\n",
      "\n",
      "11\n",
      "--------------\n",
      "Min\n",
      "--------------\n",
      "\n",
      "12\n",
      "NB_C5.txt\n",
      "--------------\n",
      "Max\n",
      "--------------\n",
      "\n",
      "12\n",
      "--------------\n",
      "Min\n",
      "--------------\n",
      "\n",
      "11\n",
      "NN_Fixed_C5.txt\n",
      "--------------\n",
      "Max\n",
      "--------------\n",
      "\n",
      "14\n",
      "--------------\n",
      "Min\n",
      "--------------\n",
      "\n",
      "14\n",
      "Cosine_Results.txt\n",
      "--------------\n",
      "Max\n",
      "--------------\n",
      "\n",
      "11\n",
      "--------------\n",
      "Min\n",
      "--------------\n",
      "\n",
      "14\n",
      "SVM_C5.txt\n",
      "--------------\n",
      "Max\n",
      "--------------\n",
      "\n",
      "12\n",
      "--------------\n",
      "Min\n",
      "--------------\n",
      "\n",
      "14\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ex = Extractor()\n",
    "    path = \"Final_Data/\"\n",
    "    all_list = []\n",
    "    for file in os.listdir(path):\n",
    "        if file[-5:] == \"5.txt\" or file[:6] == \"Cosine\": # 5 class urls\n",
    "            print(file)\n",
    "            if file[:2] == \"SV\" or file[:6] == \"Cosine\":\n",
    "                with open(path+file, \"r\") as fp:\n",
    "                    data = json.load(fp)\n",
    "            else:\n",
    "                data = ex.readDataIntoList(path+file)\n",
    "#           file = \"Final_Data/NB_C5.txt\"\n",
    "            top = 40 # total number of URLs to extract\n",
    "            try:\n",
    "                if file[:2] == \"RF\" or file[:2] == \"NN\":\n",
    "                    minscore = 3\n",
    "                    maxscore = 5\n",
    "                elif file[:6] == \"Cosine\":\n",
    "                    minscore = 0.5\n",
    "                    maxscore = 1\n",
    "                else:\n",
    "                    minscore = 4\n",
    "                    maxscore = 5\n",
    "                print(\"--------------\\nMax\\n--------------\\n\")\n",
    "                cleaned_data = ex.clean(data, minscore, maxscore, file)\n",
    "                final_list = ex.extract(cleaned_data, top)\n",
    "#                 pprint.pprint(final_list)\n",
    "                all_list += final_list\n",
    "            except:\n",
    "                print(\"ERROR\")\n",
    "            try:\n",
    "                print(\"--------------\\nMin\\n--------------\\n\")\n",
    "                if file[:2] == \"RF\" or file[:2] == \"NN\":\n",
    "                    minscore = 2\n",
    "                    maxscore = 3\n",
    "                elif file[:6] == \"Cosine\":\n",
    "                    minscore = 0.3\n",
    "                    maxscore = 0.5\n",
    "                else:\n",
    "                    minscore = 3\n",
    "                    maxscore = 4\n",
    "                cleaned_data = ex.clean(data, minscore, maxscore, file)\n",
    "                final_list = ex.extract(cleaned_data, top)\n",
    "#                 pprint.pprint(final_list)\n",
    "                all_list += final_list\n",
    "            except:\n",
    "                print(\"ERROR\")\n",
    "        \n",
    "#     pprint.pprint(all_list, indent=4)\n",
    "    print(len(all_list))\n",
    "    with open(\"Final_Data/final_list.txt\", \"a\") as fp:\n",
    "        for item in all_list:\n",
    "            fp.write(item+\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
